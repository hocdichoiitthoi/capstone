torch>=2.0.0
torchvision>=0.15.0
opencv-python>=4.9.0.80
diffusers>=0.21.0
transformers>=4.31.0
tokenizers>=0.20.3
accelerate>=0.21.0
tqdm>=4.65.0
imageio
easydict
ftfy
dashscope
imageio-ffmpeg
flash-attn>=2.3.0
gradio>=5.0.0
numpy>=1.23.5,<2
scikit-image>=0.19.0
torchmetrics>=1.0.0
pillow>=8.0.0
psutil>=5.8.0
gputil>=1.4.0
matplotlib>=3.7.0
scipy>=1.7.0
pytorch-fid>=0.3.0
av
fastapi==0.104.1
uvicorn==0.24.0
python-multipart==0.0.6
jinja2==3.1.2
aiofiles==23.2.1
pillow==10.1.0
# The following optimizations are implemented in Wan2.1:
# - RIFLEX: Built-in RoPE implementation
# - SageAttention: flash-attn>=2.3.0
# - Transformer Quantization: Local repository at /transformer-quantization-main
# - CFG-Zero-star: https://github.com/YingqingHe/CFG-Zero-star
# - TeaCache: flash-attn>=2.3.0 